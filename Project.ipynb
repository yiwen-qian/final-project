{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# IEOR 4501 Final Project: Understanding Hired Rides in NYC\n",
    "\n",
    "#### Contributors: Joy Ren(jr4154), Yiwen Qian(yq2346)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project\n",
    "\n",
    "import math\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import geopandas as gpd\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants need; some have been added for you, and \n",
    "# some you need to fill in\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "UBER_DATA = \"uber_rides_sample.csv\"\n",
    "WEATHER_CSV_DIR = \"weather\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing\n",
    "In Part 1, we downloaded Parquet files, cleaning and filtering for the relevant data, filling in missing data, and generating samples of these raw datasets.\n",
    "Our processing stages can be illustrated as:\n",
    "* 1. Load the Taxi Zones by x and y coordinates.\n",
    "* 2. Calculate distance using latitude and longtitude.\n",
    "* 3. Use `bs4` and `requests` module to parse html, then we can process Yellow Taxi data of NYC.\n",
    "* 4. Processing Uber Data.\n",
    "* 5. Processing Weather Data.\n",
    "* 6. Save the cleaned data for further analyis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_zones(shapefile):\n",
    "    return gpd.read_file(shapefile)     #read shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4622327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((933100.918 192536.086, 933091.011 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>MULTIPOLYGON (((1033269.244 172126.008, 103343...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1026308.770 256767.698, 1026495.593 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((992073.467 203714.076, 992068.667 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((935843.310 144283.336, 936046.565 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>259</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1025414.782 270986.139, 1025138.624 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>0.133514</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>260</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((1011466.966 216463.005, 1011545.889 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((980555.204 196138.486, 980570.792 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>MULTIPOLYGON (((999804.795 224498.527, 999824....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((997493.323 220912.386, 997355.264 22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0           1    0.116357    0.000782           Newark Airport           1   \n",
       "1           2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2           3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3           4    0.043567    0.000112            Alphabet City           4   \n",
       "4           5    0.092146    0.000498            Arden Heights           5   \n",
       "..        ...         ...         ...                      ...         ...   \n",
       "258       259    0.126750    0.000395       Woodlawn/Wakefield         259   \n",
       "259       260    0.133514    0.000422                 Woodside         260   \n",
       "260       261    0.027120    0.000034       World Trade Center         261   \n",
       "261       262    0.049064    0.000122           Yorkville East         262   \n",
       "262       263    0.037017    0.000066           Yorkville West         263   \n",
       "\n",
       "           borough                                           geometry  \n",
       "0              EWR  POLYGON ((933100.918 192536.086, 933091.011 19...  \n",
       "1           Queens  MULTIPOLYGON (((1033269.244 172126.008, 103343...  \n",
       "2            Bronx  POLYGON ((1026308.770 256767.698, 1026495.593 ...  \n",
       "3        Manhattan  POLYGON ((992073.467 203714.076, 992068.667 20...  \n",
       "4    Staten Island  POLYGON ((935843.310 144283.336, 936046.565 14...  \n",
       "..             ...                                                ...  \n",
       "258          Bronx  POLYGON ((1025414.782 270986.139, 1025138.624 ...  \n",
       "259         Queens  POLYGON ((1011466.966 216463.005, 1011545.889 ...  \n",
       "260      Manhattan  POLYGON ((980555.204 196138.486, 980570.792 19...  \n",
       "261      Manhattan  MULTIPOLYGON (((999804.795 224498.527, 999824....  \n",
       "262      Manhattan  POLYGON ((997493.323 220912.386, 997355.264 22...  \n",
       "\n",
       "[263 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_taxi_zones(TAXI_ZONES_SHAPEFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d04c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_coords_for_taxi_zone_id(zone_loc_id):\n",
    "    zones= load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "    centroid= zones[zones['LocationID'] == zone_loc_id].centroid.values[0]\n",
    "    return (centroid.y, centroid.x)        # return the centroid coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_with_coords(from_coord, to_coord):\n",
    "    ## \"from_coord\": columns 'pickup_latitude' and 'pickup_longitude' from datarame;\n",
    "    ## \"to_coord\":  columns 'dropoff_latitude' and 'dropoff_longitude' from datarame;\n",
    "    \n",
    "    R = 6373.0  # approximate radius of earth in km    \n",
    "    lat1, lon1 = from_coord\n",
    "    lat2, lon2 = to_coord\n",
    "\n",
    "    dlat = radians(lat2-lat1)\n",
    "    dlon = radians(lon2-lon1)\n",
    "    \n",
    "    ## Calculate the distance between two coordinates in kilometers using the Haversine formula\n",
    "    a = sin(dlat/2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * (sin(dlon/2) ** 2 )\n",
    "    coord_distance = 2 * R * atan2(math.sqrt(a), sqrt(1-a))\n",
    "    \n",
    "    return coord_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7480c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_with_zones(from_zone, to_zone):\n",
    "    ##Calculate the distance between two taxi zones in kilometers using the centroid of each zone\n",
    "    \n",
    "    from_zone_coord = lookup_coords_for_taxi_zone_id(from_zone)\n",
    "    to_zone_coord = lookup_coords_for_taxi_zone_id(to_zone)   # get two coordinates from two zone ids\n",
    "    \n",
    "    return calculate_distance_with_coords(from_zone_coord, to_zone_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f30ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_column(dataframe):               \n",
    "    distance=[]\n",
    "    for index, row in dataframe.iterrows():\n",
    "        from_coord=(row['pickup_latitude'],row['pickup_longitude'])\n",
    "        to_coord=(row['dropoff_latitude'],row['dropoff_longitude'])\n",
    "        distance.append(calculate_distance_with_coords(from_coord,to_coord))  \n",
    "    dataframe= pd.concat([dataframe,pd.DataFrame(distance,columns=['distance'])], axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data\n",
    "Here, We want to obtain the Yellow Taxi Data January 2009 through June 2015, then do the cleaning and combining to dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls_from_taxi_page(taxi_page):\n",
    "    # Get the HTML content of the page\n",
    "    res = requests.get(taxi_page)\n",
    "    soup = bs4.BeautifulSoup(res.content, 'html.parser')\n",
    "    # Find all <a> tags with href attribute\n",
    "    urls = [a['href'] for a in soup.find_all('a', href=re.compile(\".*(2009|201[0-4]|2015-0[1-6]).*\"))]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35a60f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2013-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2013-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2013-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2013-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2013-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-12.parquet']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_urls=get_all_urls_from_taxi_page(TAXI_URL)\n",
    "all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_taxi_parquet_urls(all_urls):\n",
    "    \"\"\"\n",
    "    Given a list of URLs, filters out the URLs that do not contain yellow taxi data parquet files.\n",
    "    \"\"\"\n",
    "    parquet_urls = []\n",
    "    for url in all_urls:\n",
    "        if 'yellow_tripdata' in url:\n",
    "            parquet_urls.append(url)\n",
    "    return parquet_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month(url):\n",
    "    \"\"\"\n",
    "    clean the data, and return a pandas DataFrame.\n",
    "    \"\"\"          \n",
    "\n",
    "    df = pd.read_parquet(url)\n",
    "    df = df[['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'PULocationID', 'DOLocationID', 'fare_amount']]\n",
    "    df = df.dropna()\n",
    "\n",
    "\n",
    "    \n",
    "    zone=load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "    zone = zone.to_crs(4326)\n",
    "    zone['latitude'] = zone.geometry.centroid.y\n",
    "    zone['longitude'] = zone.geometry.centroid.x\n",
    "    \n",
    "\n",
    "    # remove unnecessary columns \n",
    "    # create mapping methods for latitude & longitude\n",
    "    # aim to create lat & longitude which do not exist in some taxi data\n",
    "    zone = zone[['LocationID', 'longitude', 'latitude', 'zone', 'borough']]\n",
    "    lat_map = dict(zip(zone['LocationID'], zone['latitude']))\n",
    "    lon_map = dict(zip(zone['LocationID'], zone['longitude']))\n",
    "    \n",
    "    \n",
    "    # process dataframe which only has LocationIDs \n",
    "    # match the LocationID in 'df' with dataframe 'g'\n",
    "    # add 4 new columns to 'df' after matching\n",
    "    if 'DOLocationID' in df:\n",
    "        df['pickup_latitude']  = df['PULocationID'].map(lat_map)\n",
    "        df['pickup_longitude'] = df['PULocationID'].map(lon_map)\n",
    "        df['dropoff_latitude'] = df['DOLocationID'].map(lat_map)\n",
    "        df['dropoff_longitude']= df['DOLocationID'].map(lon_map)\n",
    "    \n",
    "    # normalizing column names\n",
    "    df = df.rename(columns={'tpep_pickup_datetime':'pickup_datetime', \n",
    "                            'Trip_Pickup_DateTime':'pickup_datetime', \n",
    "                            'tpep_dropoff_datetime':'dropoff_datetime',\n",
    "                            'Fare_Amt':'fare_amount'         \n",
    "                            })\n",
    "        \n",
    "    \n",
    "    df = df[(df['fare_amount'] >0)]     \n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['pickup_hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['pickup_day'] = df['pickup_datetime'].dt.day\n",
    "    df['pickup_weekday'] = df['pickup_datetime'].dt.weekday\n",
    "    df['pickup_month'] = df['pickup_datetime'].dt.month\n",
    "    df['pickup_year'] = df['pickup_datetime'].dt.year\n",
    "    \n",
    "    \n",
    "    #df['distance_km'] = df.apply(lambda row: calculate_distance_with_zones(row['PULocationID'], row['DOLocationID']), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6124c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_day</th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>pickup_month</th>\n",
       "      <th>pickup_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-01 00:30:05</td>\n",
       "      <td>2014-02-01 00:30:17</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>2.5</td>\n",
       "      <td>40.765484</td>\n",
       "      <td>-73.954739</td>\n",
       "      <td>40.765484</td>\n",
       "      <td>-73.954739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-01 00:16:52</td>\n",
       "      <td>2014-02-01 00:18:22</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.748497</td>\n",
       "      <td>-73.992438</td>\n",
       "      <td>40.748497</td>\n",
       "      <td>-73.992438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-01 00:05:03</td>\n",
       "      <td>2014-02-01 00:15:44</td>\n",
       "      <td>107</td>\n",
       "      <td>249</td>\n",
       "      <td>9.5</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.734576</td>\n",
       "      <td>-74.002875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-01 00:17:19</td>\n",
       "      <td>2014-02-01 00:20:15</td>\n",
       "      <td>158</td>\n",
       "      <td>90</td>\n",
       "      <td>4.5</td>\n",
       "      <td>40.735035</td>\n",
       "      <td>-74.008984</td>\n",
       "      <td>40.742279</td>\n",
       "      <td>-73.996971</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-02-01 00:24:08</td>\n",
       "      <td>2014-02-01 00:37:07</td>\n",
       "      <td>234</td>\n",
       "      <td>246</td>\n",
       "      <td>11.5</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.990458</td>\n",
       "      <td>40.753309</td>\n",
       "      <td>-74.004015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063789</th>\n",
       "      <td>2014-02-28 23:15:00</td>\n",
       "      <td>2014-02-28 23:38:00</td>\n",
       "      <td>231</td>\n",
       "      <td>61</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.717773</td>\n",
       "      <td>-74.007880</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063790</th>\n",
       "      <td>2014-02-28 23:53:00</td>\n",
       "      <td>2014-03-01 00:12:00</td>\n",
       "      <td>225</td>\n",
       "      <td>177</td>\n",
       "      <td>14.0</td>\n",
       "      <td>40.688168</td>\n",
       "      <td>-73.931888</td>\n",
       "      <td>40.676644</td>\n",
       "      <td>-73.913632</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063791</th>\n",
       "      <td>2014-02-28 23:12:00</td>\n",
       "      <td>2014-02-28 23:29:00</td>\n",
       "      <td>181</td>\n",
       "      <td>71</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.670374</td>\n",
       "      <td>-73.981414</td>\n",
       "      <td>40.644288</td>\n",
       "      <td>-73.937966</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063792</th>\n",
       "      <td>2014-02-28 23:20:56</td>\n",
       "      <td>2014-02-28 23:55:20</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>27.5</td>\n",
       "      <td>40.761102</td>\n",
       "      <td>-73.828859</td>\n",
       "      <td>40.761102</td>\n",
       "      <td>-73.828859</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063793</th>\n",
       "      <td>2014-02-28 23:59:22</td>\n",
       "      <td>2014-03-01 00:15:48</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>14.0</td>\n",
       "      <td>40.761102</td>\n",
       "      <td>-73.828859</td>\n",
       "      <td>40.761102</td>\n",
       "      <td>-73.828859</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13063794 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pickup_datetime    dropoff_datetime  PULocationID  DOLocationID  \\\n",
       "0        2014-02-01 00:30:05 2014-02-01 00:30:17           140           140   \n",
       "1        2014-02-01 00:16:52 2014-02-01 00:18:22           186           186   \n",
       "2        2014-02-01 00:05:03 2014-02-01 00:15:44           107           249   \n",
       "3        2014-02-01 00:17:19 2014-02-01 00:20:15           158            90   \n",
       "4        2014-02-01 00:24:08 2014-02-01 00:37:07           234           246   \n",
       "...                      ...                 ...           ...           ...   \n",
       "13063789 2014-02-28 23:15:00 2014-02-28 23:38:00           231            61   \n",
       "13063790 2014-02-28 23:53:00 2014-03-01 00:12:00           225           177   \n",
       "13063791 2014-02-28 23:12:00 2014-02-28 23:29:00           181            71   \n",
       "13063792 2014-02-28 23:20:56 2014-02-28 23:55:20            92            92   \n",
       "13063793 2014-02-28 23:59:22 2014-03-01 00:15:48            92            92   \n",
       "\n",
       "          fare_amount  pickup_latitude  pickup_longitude  dropoff_latitude  \\\n",
       "0                 2.5        40.765484        -73.954739         40.765484   \n",
       "1                 3.0        40.748497        -73.992438         40.748497   \n",
       "2                 9.5        40.736824        -73.984052         40.734576   \n",
       "3                 4.5        40.735035        -74.008984         40.742279   \n",
       "4                11.5        40.740337        -73.990458         40.753309   \n",
       "...               ...              ...               ...               ...   \n",
       "13063789         21.0        40.717773        -74.007880         40.674469   \n",
       "13063790         14.0        40.688168        -73.931888         40.676644   \n",
       "13063791         16.0        40.670374        -73.981414         40.644288   \n",
       "13063792         27.5        40.761102        -73.828859         40.761102   \n",
       "13063793         14.0        40.761102        -73.828859         40.761102   \n",
       "\n",
       "          dropoff_longitude  pickup_hour  pickup_day  pickup_weekday  \\\n",
       "0                -73.954739            0           1               5   \n",
       "1                -73.992438            0           1               5   \n",
       "2                -74.002875            0           1               5   \n",
       "3                -73.996971            0           1               5   \n",
       "4                -74.004015            0           1               5   \n",
       "...                     ...          ...         ...             ...   \n",
       "13063789         -73.939287           23          28               4   \n",
       "13063790         -73.913632           23          28               4   \n",
       "13063791         -73.937966           23          28               4   \n",
       "13063792         -73.828859           23          28               4   \n",
       "13063793         -73.828859           23          28               4   \n",
       "\n",
       "          pickup_month  pickup_year  \n",
       "0                    2         2014  \n",
       "1                    2         2014  \n",
       "2                    2         2014  \n",
       "3                    2         2014  \n",
       "4                    2         2014  \n",
       "...                ...          ...  \n",
       "13063789             2         2014  \n",
       "13063790             2         2014  \n",
       "13063791             2         2014  \n",
       "13063792             2         2014  \n",
       "13063793             2         2014  \n",
       "\n",
       "[13063794 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_and_clean_month(\"yellow taxi/yellow_tripdata_2014-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data(parquet_urls):\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    for parquet_url in parquet_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month(parquet_url)\n",
    "    \n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        add_distance_column(dataframe)\n",
    "        \n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "200776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxi_data():\n",
    "    # download file if not exist\n",
    "    all_urls = get_all_urls_from_taxi_page(TAXI_URL)\n",
    "    all_parquet_urls = filter_taxi_parquet_urls(all_urls)\n",
    "    for url in all_parquet_urls:\n",
    "        response = requests.get(url, stream=True)\n",
    "        file_name = url.split(\"/\")[-1]\n",
    "        local_file_path = os.path.join(\"yellow taxi\", file_name)\n",
    "        if not os.path.exists(local_file_path):\n",
    "            with open(local_file_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "    \n",
    "    \n",
    "    taxi_data = get_and_clean_taxi_data(all_parquet_urls)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1028d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = get_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ebd75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df.dropna(how='any')      #remove missing values\n",
    "    df = df.drop(columns=['Unnamed: 0','key','passenger_count'])      #remove unnecessary columns\n",
    "    df = df.loc[df.pickup_longitude.between(-74.242330,-73.717047) & df.dropoff_longitude.between(-74.242330,-73.717047) \n",
    "         & df.pickup_latitude.between(40.560445,40.908524)& df.dropoff_latitude.between(40.560445,40.908524)]\n",
    "          # remove locations out of range\n",
    "    df.reset_index(drop=True, inplace=True)    #reset index\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_DATA)\n",
    "    uber_dataframe = add_distance_column(uber_dataframe)\n",
    "    uber_dataframe[\"pickup_datetime\"] = pd.to_datetime(uber_dataframe['pickup_datetime'])\n",
    "    uber_dataframe[\"year\"] = uber_dataframe[\"pickup_datetime\"].dt.year\n",
    "    uber_dataframe[\"month\"] = uber_dataframe[\"pickup_datetime\"].dt.month\n",
    "    uber_dataframe[\"day\"] = uber_dataframe[\"pickup_datetime\"].dt.day\n",
    "    uber_dataframe[\"hour\"] = uber_dataframe[\"pickup_datetime\"].dt.hour\n",
    "    uber_dataframe[\"dayofweek\"] = uber_dataframe[\"pickup_datetime\"].dt.dayofweek\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c2bd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "339997e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>distance</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1.683851</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>2.458361</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>5.037958</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>1.662205</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>4.476855</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0          7.5 2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1          7.7 2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2         12.9 2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3          5.3 2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4         16.0 2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  distance  year  month  day  hour  \\\n",
       "0         -73.999512         40.723217  1.683851  2015      5    7    19   \n",
       "1         -73.994710         40.750325  2.458361  2009      7   17    20   \n",
       "2         -73.962565         40.772647  5.037958  2009      8   24    21   \n",
       "3         -73.965316         40.803349  1.662205  2009      6   26     8   \n",
       "4         -73.973082         40.761247  4.476855  2014      8   28    17   \n",
       "\n",
       "   dayofweek  \n",
       "0          3  \n",
       "1          4  \n",
       "2          0  \n",
       "3          4  \n",
       "4          3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weather_csvs(directory):\n",
    "    csv_files = [file for file in os.listdir(directory) if file.endswith(\".csv\")]\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d990317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2012_weather.csv',\n",
       " '2011_weather.csv',\n",
       " '2014_weather.csv',\n",
       " '2013_weather.csv',\n",
       " '2009_weather.csv',\n",
       " '2015_weather.csv',\n",
       " '2010_weather.csv']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the \"weather\" csv files from 2009-2015\n",
    "get_all_weather_csvs(WEATHER_CSV_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # remove columns that have all NaN values\n",
    "    df=df.dropna(axis=1, how=\"all\")\n",
    "    \n",
    "    # for \"hourly wind speed\", fill missing value (calculate hourly-data from daily-data)\n",
    "    if df['HourlyWindSpeed'] is 'NaN':\n",
    "        df['HourlyWindSpeed'] = df['DailyAverageWindSpeed']/24\n",
    "        df['HourlyWindSpeed'].apply(lambda x: round(x,2))\n",
    "        \n",
    "    # only keep necessary columns\n",
    "    keep = ['DATE', 'HourlyPrecipitation', 'HourlyWindSpeed']\n",
    "    \n",
    "    #in \"hourly precipation\" column, replace \"T\" with value 0, replace NaN with 0 since existing value \n",
    "    # for the column is small\n",
    "    df['HourlyPrecipitation'] = df['HourlyPrecipitation'].replace({pd.np.nan: 0, 'T': 0})\n",
    "    df['HourlyPrecipitation'] = df['HourlyPrecipitation'].apply(  lambda x: x.replace('s', '') \n",
    "                                                                if isinstance(x, str) else x)\n",
    "    df['HourlyPrecipitation'] = df['HourlyPrecipitation'].astype(float)\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    for i in keep:\n",
    "        col1=df.loc[:,df.columns.str.contains(i)]\n",
    "        df1=pd.concat([df1, col1], axis=1)\n",
    "    hourly_clean= df1.dropna()\n",
    "    hourly_clean.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Add columns of year, month, day and hour\n",
    "    hourly_clean[\"DATE\"] = pd.to_datetime(hourly_clean['DATE'])\n",
    "    hourly_clean[\"YEAR\"] = hourly_clean[\"DATE\"].dt.year\n",
    "    hourly_clean[\"MONTH\"] = hourly_clean[\"DATE\"].dt.month\n",
    "    hourly_clean[\"DAY\"] = hourly_clean[\"DATE\"].dt.day\n",
    "    hourly_clean[\"HOUR\"] = hourly_clean[\"DATE\"].dt.hour\n",
    "    hourly_clean['HourlyPrecipitation'] = hourly_clean['HourlyPrecipitation'].round(2)\n",
    "    hourly_clean.dropna(inplace=True)\n",
    "    return hourly_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "301e093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01 00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01 01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01 02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01 03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01 04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>2012-12-31 18:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>2012-12-31 19:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>2012-12-31 20:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>2012-12-31 21:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>2012-12-31 23:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10208 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DATE  HourlyPrecipitation  HourlyWindSpeed  YEAR  MONTH  \\\n",
       "0     2012-01-01 00:51:00                  0.0              6.0  2012      1   \n",
       "1     2012-01-01 01:51:00                  0.0              7.0  2012      1   \n",
       "2     2012-01-01 02:51:00                  0.0              6.0  2012      1   \n",
       "3     2012-01-01 03:51:00                  0.0              5.0  2012      1   \n",
       "4     2012-01-01 04:51:00                  0.0              0.0  2012      1   \n",
       "...                   ...                  ...              ...   ...    ...   \n",
       "10203 2012-12-31 18:51:00                  0.0              9.0  2012     12   \n",
       "10204 2012-12-31 19:51:00                  0.0              9.0  2012     12   \n",
       "10205 2012-12-31 20:51:00                  0.0              8.0  2012     12   \n",
       "10206 2012-12-31 21:51:00                  0.0              7.0  2012     12   \n",
       "10207 2012-12-31 23:51:00                  0.0              6.0  2012     12   \n",
       "\n",
       "       DAY  HOUR  \n",
       "0        1     0  \n",
       "1        1     1  \n",
       "2        1     2  \n",
       "3        1     3  \n",
       "4        1     4  \n",
       "...    ...   ...  \n",
       "10203   31    18  \n",
       "10204   31    19  \n",
       "10205   31    20  \n",
       "10206   31    21  \n",
       "10207   31    23  \n",
       "\n",
       "[10208 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_month_weather_data_hourly('weather/2012_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    #remove columns having all NaN values\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    \n",
    "    #in \"hourly precipation\" column, replace \"T\" with value 0, replace NaN with 0 since existing value \n",
    "    # for the column is small\n",
    "    df['HourlyPrecipitation'] = df['HourlyPrecipitation'].replace({pd.np.nan: 0, 'T': 0})\n",
    "    df['HourlyPrecipitation'] = df['HourlyPrecipitation'].apply(  lambda x: x.replace('s', '') \n",
    "                                                                if isinstance(x, str) else x)\n",
    "    df['HourlyPrecipitation'] = df['HourlyPrecipitation'].astype(float)\n",
    "    \n",
    "    df['DATE'] = pd.to_datetime(df['DATE']) \n",
    "    df['DATE'] = df['DATE'].apply(lambda x: x.date())\n",
    "    \n",
    "    # Group by same date, calculate the mean,use that number as daily data\n",
    "    Daily_w = df.groupby('DATE')['HourlyWindSpeed'].mean()\n",
    "    Daily_p = df.groupby('DATE')['HourlyPrecipitation'].mean()\n",
    "    #df1 = df.drop_duplicates(subset=['DATE'])\n",
    "    df = df[['DATE']]\n",
    "    df = pd.merge(df, Daily_w, on='DATE')\n",
    "    df= pd.merge(df, Daily_p, on='DATE')\n",
    "    \n",
    "    df.rename(columns={'HourlyWindSpeed':'DailyWindSpeed','HourlyPrecipitation':'DailyPrecipitation'},inplace=True)\n",
    "    \n",
    "    df['DailyWindSpeed'] = df['DailyWindSpeed'].round(2)\n",
    "    df['DailyPrecipitation'] = df['DailyPrecipitation'].round(2)\n",
    "    \n",
    "    # Add columns of year, month, day and hour\n",
    "    df[\"DATE\"] = pd.to_datetime(df['DATE'])\n",
    "    df[\"YEAR\"] = df[\"DATE\"].dt.year\n",
    "    df[\"MONTH\"] = df[\"DATE\"].dt.month\n",
    "    df[\"DAY\"] = df[\"DATE\"].dt.day\n",
    "    df[\"HOUR\"] = df[\"DATE\"].dt.hour\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "610c932a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>DailyWindSpeed</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10687</th>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10688</th>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10689</th>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10690</th>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10691</th>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10692 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE  DailyWindSpeed  DailyPrecipitation  YEAR  MONTH  DAY  HOUR\n",
       "0     2012-01-01            5.87                 0.0  2012      1    1     0\n",
       "1     2012-01-01            5.87                 0.0  2012      1    1     0\n",
       "2     2012-01-01            5.87                 0.0  2012      1    1     0\n",
       "3     2012-01-01            5.87                 0.0  2012      1    1     0\n",
       "4     2012-01-01            5.87                 0.0  2012      1    1     0\n",
       "...          ...             ...                 ...   ...    ...  ...   ...\n",
       "10687 2012-12-31            7.52                 0.0  2012     12   31     0\n",
       "10688 2012-12-31            7.52                 0.0  2012     12   31     0\n",
       "10689 2012-12-31            7.52                 0.0  2012     12   31     0\n",
       "10690 2012-12-31            7.52                 0.0  2012     12   31     0\n",
       "10691 2012-12-31            7.52                 0.0  2012     12   31     0\n",
       "\n",
       "[10692 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_month_weather_data_daily('weather/2012_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    weather_csv_files = get_all_weather_csvs(WEATHER_CSV_DIR)\n",
    "    \n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "        \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(WEATHER_CSV_DIR+\"/\"+csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(WEATHER_CSV_DIR+\"/\"+csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48216557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01 00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01 01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01 02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01 03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01 04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATE  HourlyPrecipitation  HourlyWindSpeed  YEAR  MONTH  DAY  \\\n",
       "0 2012-01-01 00:51:00                  0.0              6.0  2012      1    1   \n",
       "1 2012-01-01 01:51:00                  0.0              7.0  2012      1    1   \n",
       "2 2012-01-01 02:51:00                  0.0              6.0  2012      1    1   \n",
       "3 2012-01-01 03:51:00                  0.0              5.0  2012      1    1   \n",
       "4 2012-01-01 04:51:00                  0.0              0.0  2012      1    1   \n",
       "\n",
       "   HOUR  \n",
       "0     0  \n",
       "1     1  \n",
       "2     2  \n",
       "3     3  \n",
       "4     4  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cb386ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>DailyWindSpeed</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  DailyWindSpeed  DailyPrecipitation  YEAR  MONTH  DAY  HOUR\n",
       "0 2012-01-01            5.87                 0.0  2012      1    1     0\n",
       "1 2012-01-01            5.87                 0.0  2012      1    1     0\n",
       "2 2012-01-01            5.87                 0.0  2012      1    1     0\n",
       "3 2012-01-01            5.87                 0.0  2012      1    1     0\n",
       "4 2012-01-01            5.87                 0.0  2012      1    1     0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    DATE DATE,\n",
    "    HourlyPrecipitation FLOAT,\n",
    "    HourlyWindSpeed FLOAT,\n",
    "    YEAR INTEGER,\n",
    "    MONTH INTEGER,\n",
    "    DAY INTEGER,\n",
    "    HOUR INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    DATE DATE,\n",
    "    DailyWindSpeed FLOAT,\n",
    "    DailyPrecipitation FLOAT,\n",
    "    YEAR INTEGER,\n",
    "    MONTH INTEGER,\n",
    "    DAY INTEGER,\n",
    "    HOUR INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    pickup_datetime DATE,\n",
    "    dropoff_datetime DATE,\n",
    "    PULocationID INTEGER,\n",
    "    DOLocationID INTEGER,\n",
    "    fare_amount FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    pickup_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    distance FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    fare_amount FLOAT,\n",
    "    pickup_datetime DATETIME,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT,\n",
    "    distance FLOAT,\n",
    "    year INTEGER,\n",
    "    month INTEGER,\n",
    "    day INTEGER,\n",
    "    hour INTEGER,\n",
    "    dayofweek INTEGER\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    afile = open(DATABASE_SCHEMA_FILE, 'r')\n",
    "    sqlFile = afile.read()\n",
    "    afile.close()\n",
    "\n",
    "    sqlQuery = sqlFile.split(';')\n",
    "    for query in sqlQuery:\n",
    "        connection.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    for table, df in table_to_df_dict.items():\n",
    "        df.to_sql(table, engine,if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    #\"taxi_trips\": taxi_data,                 taxi数据没好\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_weather_data,\n",
    "    \"daily_weather\": daily_weather_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    with open(QUERY_DIRECTORY + outfile, \"w\") as f:\n",
    "        f.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1:For 01-2009 through 06-2015, show the popularity of Yellow Taxi rides for each hour of the day. The query result should have 24 bins, one for each hour, descending.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7df5e",
   "metadata": {},
   "source": [
    "### Query 2: For the same time frame, show the popularity of Uber rides for each day of the week.The result should have 7 bins, one for each day, descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c7f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75c408b5",
   "metadata": {},
   "source": [
    "### Query 3: What is the 95% percentile of distance traveled for all hired trips during July 2013? The result should be a float. It’s okay if it’s a single float within a list and/or tuple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47288658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d0ea818",
   "metadata": {},
   "source": [
    "### Query 4:  What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e8d89f",
   "metadata": {},
   "source": [
    "#### The result should be a list of 10 tuples. Each tuple should have three items: a date, an integer for the number of rides of that date, and a float for the average distance of that date. The list of tuples should be sorted by total number of rides, descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d2f070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ccbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ed7df16",
   "metadata": {},
   "source": [
    "### Query 5: Which 10 days in 2014 were the windiest on average, and how many hired trips were made on those days? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746cfe8",
   "metadata": {},
   "source": [
    "#### The result should be a list of 10 tuples. Each tuple should have three items: a date, a float for the average wind speed of that day, and the number of hired trips for that day. The list of tuples should be sorted by the average wind speed, descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5be71c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65db3fcb",
   "metadata": {},
   "source": [
    "### Query 6: During Hurricane Sandy in NYC (Oct 29-30, 2012), plus the week leading up and the week after, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a0431",
   "metadata": {},
   "source": [
    "#### The result should be a list of roughly 384 tuples, where each tuple is an entry for every single hour of the given date range, even if no rides were taken, no precipitation was measured, or there was no wind. Each tuple should have four items: a string for the date and hour, an int for the number of hired rides in that hour, the float for the total precipitation for that hour, and a float for the average wind speed for that hour. The list of tuples should be ordered by date+hour, ascending.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6e2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394d824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2c3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
