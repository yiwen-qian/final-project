{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# IEOR 4501 Final Project: Understanding Hired Rides in NYC\n",
    "\n",
    "#### Contributors: Joy Ren(jr4154), Yiwen Qian(yq2346)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project\n",
    "\n",
    "import math\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import geopandas as gpd\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants need; some have been added for you, and \n",
    "# some you need to fill in\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "UBER_DATA = \"uber_rides_sample.csv\"\n",
    "WEATHER_CSV_DIR = \"weather\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing\n",
    "In Part 1, we downloaded Parquet files, cleaning and filtering for the relevant data, filling in missing data, and generating samples of these raw datasets.\n",
    "Our processing stages can be illustrated as:\n",
    "* 1. Load the Taxi Zones by x and y coordinates.\n",
    "* 2. Calculate distance using latitude and longtitude.\n",
    "* 3. Use `bs4` and `requests` module to parse html, then we can process Yellow Taxi data of NYC.\n",
    "* 4. Processing Uber Data.\n",
    "* 5. Processing Weather Data.\n",
    "* 6. Save the cleaned data for further analyis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_zones(shapefile):\n",
    "    return gpd.read_file(shapefile)     #read shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4622327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((933100.918 192536.086, 933091.011 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>MULTIPOLYGON (((1033269.244 172126.008, 103343...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1026308.770 256767.698, 1026495.593 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((992073.467 203714.076, 992068.667 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((935843.310 144283.336, 936046.565 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>259</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1025414.782 270986.139, 1025138.624 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>0.133514</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>260</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((1011466.966 216463.005, 1011545.889 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((980555.204 196138.486, 980570.792 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>MULTIPOLYGON (((999804.795 224498.527, 999824....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((997493.323 220912.386, 997355.264 22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0           1    0.116357    0.000782           Newark Airport           1   \n",
       "1           2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2           3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3           4    0.043567    0.000112            Alphabet City           4   \n",
       "4           5    0.092146    0.000498            Arden Heights           5   \n",
       "..        ...         ...         ...                      ...         ...   \n",
       "258       259    0.126750    0.000395       Woodlawn/Wakefield         259   \n",
       "259       260    0.133514    0.000422                 Woodside         260   \n",
       "260       261    0.027120    0.000034       World Trade Center         261   \n",
       "261       262    0.049064    0.000122           Yorkville East         262   \n",
       "262       263    0.037017    0.000066           Yorkville West         263   \n",
       "\n",
       "           borough                                           geometry  \n",
       "0              EWR  POLYGON ((933100.918 192536.086, 933091.011 19...  \n",
       "1           Queens  MULTIPOLYGON (((1033269.244 172126.008, 103343...  \n",
       "2            Bronx  POLYGON ((1026308.770 256767.698, 1026495.593 ...  \n",
       "3        Manhattan  POLYGON ((992073.467 203714.076, 992068.667 20...  \n",
       "4    Staten Island  POLYGON ((935843.310 144283.336, 936046.565 14...  \n",
       "..             ...                                                ...  \n",
       "258          Bronx  POLYGON ((1025414.782 270986.139, 1025138.624 ...  \n",
       "259         Queens  POLYGON ((1011466.966 216463.005, 1011545.889 ...  \n",
       "260      Manhattan  POLYGON ((980555.204 196138.486, 980570.792 19...  \n",
       "261      Manhattan  MULTIPOLYGON (((999804.795 224498.527, 999824....  \n",
       "262      Manhattan  POLYGON ((997493.323 220912.386, 997355.264 22...  \n",
       "\n",
       "[263 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_taxi_zones(TAXI_ZONES_SHAPEFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d04c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_coords_for_taxi_zone_id(zone_loc_id):\n",
    "    zones= load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "    centroid= zones[zones['LocationID'] == zone_loc_id].centroid.values[0]\n",
    "    return (centroid.y, centroid.x)        # return the centroid coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_with_coords(from_coord, to_coord):\n",
    "    ## \"from_coord\": columns 'pickup_latitude' and 'pickup_longitude' from datarame;\n",
    "    ## \"to_coord\":  columns 'dropoff_latitude' and 'dropoff_longitude' from datarame;\n",
    "    \n",
    "    R = 6373.0  # approximate radius of earth in km    \n",
    "    lat1, lon1 = from_coord\n",
    "    lat2, lon2 = to_coord\n",
    "\n",
    "    dlat = radians(lat2-lat1)\n",
    "    dlon = radians(lon2-lon1)\n",
    "    \n",
    "    ## Calculate the distance between two coordinates in kilometers using the Haversine formula\n",
    "    a = sin(dlat/2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * (sin(dlon/2) ** 2 )\n",
    "    coord_distance = 2 * R * atan2(math.sqrt(a), sqrt(1-a))\n",
    "    \n",
    "    return coord_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7480c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_with_zones(from_zone, to_zone):\n",
    "    ##Calculate the distance between two taxi zones in kilometers using the centroid of each zone\n",
    "    \n",
    "    from_zone_coord = lookup_coords_for_taxi_zone_id(from_zone)\n",
    "    to_zone_coord = lookup_coords_for_taxi_zone_id(to_zone)   # get two coordinates from two zone ids\n",
    "    \n",
    "    return calculate_distance_with_coords(from_zone_coord, to_zone_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f30ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_column(dataframe):               \n",
    "    distance=[]\n",
    "    for index, row in dataframe.iterrows():\n",
    "        from_coord=(row['pickup_latitude'],row['pickup_longitude'])\n",
    "        to_coord=(row['dropoff_latitude'],row['dropoff_longitude'])\n",
    "        distance.append(calculate_distance_with_coords(from_coord,to_coord))  \n",
    "    dataframe= pd.concat([dataframe,pd.DataFrame(distance,columns=['distance'])], axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdc688b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:30:05</td>\n",
       "      <td>2014-02-01 00:30:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:16:52</td>\n",
       "      <td>2014-02-01 00:18:22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:05:03</td>\n",
       "      <td>2014-02-01 00:15:44</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:17:19</td>\n",
       "      <td>2014-02-01 00:20:15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>158</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:24:08</td>\n",
       "      <td>2014-02-01 00:37:07</td>\n",
       "      <td>2</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>234</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063789</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-28 23:15:00</td>\n",
       "      <td>2014-02-28 23:38:00</td>\n",
       "      <td>1</td>\n",
       "      <td>5.67</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>231</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063790</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-28 23:53:00</td>\n",
       "      <td>2014-03-01 00:12:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>225</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063791</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-28 23:12:00</td>\n",
       "      <td>2014-02-28 23:29:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>181</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063792</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-28 23:20:56</td>\n",
       "      <td>2014-02-28 23:55:20</td>\n",
       "      <td>1</td>\n",
       "      <td>7.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063793</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-28 23:59:22</td>\n",
       "      <td>2014-03-01 00:15:48</td>\n",
       "      <td>1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13063794 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0                1  2014-02-01 00:30:05   2014-02-01 00:30:17   \n",
       "1                1  2014-02-01 00:16:52   2014-02-01 00:18:22   \n",
       "2                1  2014-02-01 00:05:03   2014-02-01 00:15:44   \n",
       "3                1  2014-02-01 00:17:19   2014-02-01 00:20:15   \n",
       "4                1  2014-02-01 00:24:08   2014-02-01 00:37:07   \n",
       "...            ...                  ...                   ...   \n",
       "13063789         2  2014-02-28 23:15:00   2014-02-28 23:38:00   \n",
       "13063790         2  2014-02-28 23:53:00   2014-03-01 00:12:00   \n",
       "13063791         2  2014-02-28 23:12:00   2014-02-28 23:29:00   \n",
       "13063792         1  2014-02-28 23:20:56   2014-02-28 23:55:20   \n",
       "13063793         1  2014-02-28 23:59:22   2014-03-01 00:15:48   \n",
       "\n",
       "          passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                       1           0.00           1                  N   \n",
       "1                       1           0.00           1                  N   \n",
       "2                       1           2.00           1                  N   \n",
       "3                       1           0.70           1                  N   \n",
       "4                       2           2.40           1                  N   \n",
       "...                   ...            ...         ...                ...   \n",
       "13063789                1           5.67           1               None   \n",
       "13063790                1           1.96           1               None   \n",
       "13063791                1           4.06           1               None   \n",
       "13063792                1           7.20           1                  N   \n",
       "13063793                1           3.20           1                  N   \n",
       "\n",
       "          PULocationID  DOLocationID  payment_type  fare_amount  extra  \\\n",
       "0                  140           140             2          2.5    0.5   \n",
       "1                  186           186             2          3.0    0.5   \n",
       "2                  107           249             1          9.5    0.5   \n",
       "3                  158            90             1          4.5    0.5   \n",
       "4                  234           246             1         11.5    0.5   \n",
       "...                ...           ...           ...          ...    ...   \n",
       "13063789           231            61             1         21.0    0.5   \n",
       "13063790           225           177             2         14.0    0.5   \n",
       "13063791           181            71             1         16.0    0.5   \n",
       "13063792            92            92             2         27.5    0.5   \n",
       "13063793            92            92             1         14.0    0.5   \n",
       "\n",
       "          mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "0             0.5         0.0           0.0                    0.0   \n",
       "1             0.5         0.0           0.0                    0.0   \n",
       "2             0.5         2.1           0.0                    0.0   \n",
       "3             0.5         1.5           0.0                    0.0   \n",
       "4             0.5         2.5           0.0                    0.0   \n",
       "...           ...         ...           ...                    ...   \n",
       "13063789      0.5         4.0           0.0                    0.0   \n",
       "13063790      0.5         0.0           0.0                    0.0   \n",
       "13063791      0.5         0.0           0.0                    0.0   \n",
       "13063792      0.5         0.0           0.0                    0.0   \n",
       "13063793      0.5         2.5           0.0                    0.0   \n",
       "\n",
       "          total_amount congestion_surcharge airport_fee  \n",
       "0                  3.5                 None        None  \n",
       "1                  4.0                 None        None  \n",
       "2                 12.6                 None        None  \n",
       "3                  7.0                 None        None  \n",
       "4                 15.0                 None        None  \n",
       "...                ...                  ...         ...  \n",
       "13063789          26.0                 None        None  \n",
       "13063790          15.0                 None        None  \n",
       "13063791          17.0                 None        None  \n",
       "13063792          28.5                 None        None  \n",
       "13063793          17.5                 None        None  \n",
       "\n",
       "[13063794 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=pd.read_parquet(\"yellow taxi/yellow_tripdata_2014-02.parquet\")\n",
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data\n",
    "Here, We want to obtain the Yellow Taxi Data January 2009 through June 2015, then do the cleaning and combining to dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dd682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls_from_taxi_page(taxi_page):\n",
    "    # Get the HTML content of the page\n",
    "    res = requests.get(taxi_page)\n",
    "    soup = bs4.BeautifulSoup(res.content, 'html.parser')\n",
    "    # Find all <a> tags with href attribute\n",
    "    urls = [a['href'] for a in soup.find_all('a', href=re.compile(\".*(2009|201[0-4]|2015-0[1-6]).*\"))]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a60f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2014-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2013-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2013-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2013-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2013-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2013-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-12.parquet']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_urls=get_all_urls_from_taxi_page(TAXI_URL)\n",
    "all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_taxi_parquet_urls(all_urls):\n",
    "    \"\"\"\n",
    "    Given a list of URLs, filters out the URLs that do not contain yellow taxi data parquet files.\n",
    "    \"\"\"\n",
    "    parquet_urls = []\n",
    "    for url in all_urls:\n",
    "        if 'yellow_tripdata' in url:\n",
    "            parquet_urls.append(url)\n",
    "    return parquet_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month(url):\n",
    "    \"\"\"\n",
    "    clean the data, and return a pandas DataFrame.\n",
    "    \"\"\"          \n",
    "\n",
    "    df = pd.read_parquet(url)\n",
    "    df = df[['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'PULocationID', 'DOLocationID', 'fare_amount']]\n",
    "    df = df.dropna()\n",
    "\n",
    "\n",
    "    \n",
    "    zone=load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "    zone = zone.to_crs(4326)\n",
    "    zone['latitude'] = zone.geometry.centroid.y\n",
    "    zone['longitude'] = zone.geometry.centroid.x\n",
    "    \n",
    "\n",
    "    # remove unnecessary columns \n",
    "    # create mapping methods for latitude & longitude\n",
    "    # aim to create lat & longitude which do not exist in some taxi data\n",
    "    zone = zone[['LocationID', 'longitude', 'latitude', 'zone', 'borough']]\n",
    "    lat_map = dict(zip(zone['LocationID'], zone['latitude']))\n",
    "    lon_map = dict(zip(zone['LocationID'], zone['longitude']))\n",
    "    \n",
    "    \n",
    "    # process dataframe which only has LocationIDs \n",
    "    # match the LocationID in 'df' with dataframe 'g'\n",
    "    # add 4 new columns to 'df' after matching\n",
    "    if 'DOLocationID' in df:\n",
    "        df['pickup_latitude']  = df['PULocationID'].map(lat_map)\n",
    "        df['pickup_longitude'] = df['PULocationID'].map(lon_map)\n",
    "        df['dropoff_latitude'] = df['DOLocationID'].map(lat_map)\n",
    "        df['dropoff_longitude']= df['DOLocationID'].map(lon_map)\n",
    "    \n",
    "    # normalizing column names\n",
    "    df = df.rename(columns={'tpep_pickup_datetime':'pickup_datetime', \n",
    "                            'Trip_Pickup_DateTime':'pickup_datetime', \n",
    "                            'tpep_dropoff_datetime':'dropoff_datetime',\n",
    "                            'Fare_Amt':'fare_amount'         \n",
    "                            })\n",
    "        \n",
    "    \n",
    "    df = df[(df['fare_amount'] >0)]     \n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['pickup_hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['pickup_day'] = df['pickup_datetime'].dt.day\n",
    "    df['pickup_weekday'] = df['pickup_datetime'].dt.weekday\n",
    "    df['pickup_month'] = df['pickup_datetime'].dt.month\n",
    "    df['pickup_year'] = df['pickup_datetime'].dt.year\n",
    "    df['pickup_date'] = df['pickup_datetime'].dt.date\n",
    "    df['pickup_time'] = df['pickup_datetime'].dt.time\n",
    "    \n",
    "   \n",
    "    \n",
    "    #df['distance_km'] = df.apply(lambda row: calculate_distance_with_zones(row['PULocationID'], row['DOLocationID']), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a21ced7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:30:05</td>\n",
       "      <td>2014-02-01 00:30:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:16:52</td>\n",
       "      <td>2014-02-01 00:18:22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:05:03</td>\n",
       "      <td>2014-02-01 00:15:44</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:17:19</td>\n",
       "      <td>2014-02-01 00:20:15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>158</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:24:08</td>\n",
       "      <td>2014-02-01 00:37:07</td>\n",
       "      <td>2</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>234</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063789</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-28 23:15:00</td>\n",
       "      <td>2014-02-28 23:38:00</td>\n",
       "      <td>1</td>\n",
       "      <td>5.67</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>231</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063790</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-28 23:53:00</td>\n",
       "      <td>2014-03-01 00:12:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>225</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063791</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-28 23:12:00</td>\n",
       "      <td>2014-02-28 23:29:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>181</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063792</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-28 23:20:56</td>\n",
       "      <td>2014-02-28 23:55:20</td>\n",
       "      <td>1</td>\n",
       "      <td>7.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063793</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-28 23:59:22</td>\n",
       "      <td>2014-03-01 00:15:48</td>\n",
       "      <td>1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13063794 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0                1  2014-02-01 00:30:05   2014-02-01 00:30:17   \n",
       "1                1  2014-02-01 00:16:52   2014-02-01 00:18:22   \n",
       "2                1  2014-02-01 00:05:03   2014-02-01 00:15:44   \n",
       "3                1  2014-02-01 00:17:19   2014-02-01 00:20:15   \n",
       "4                1  2014-02-01 00:24:08   2014-02-01 00:37:07   \n",
       "...            ...                  ...                   ...   \n",
       "13063789         2  2014-02-28 23:15:00   2014-02-28 23:38:00   \n",
       "13063790         2  2014-02-28 23:53:00   2014-03-01 00:12:00   \n",
       "13063791         2  2014-02-28 23:12:00   2014-02-28 23:29:00   \n",
       "13063792         1  2014-02-28 23:20:56   2014-02-28 23:55:20   \n",
       "13063793         1  2014-02-28 23:59:22   2014-03-01 00:15:48   \n",
       "\n",
       "          passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                       1           0.00           1                  N   \n",
       "1                       1           0.00           1                  N   \n",
       "2                       1           2.00           1                  N   \n",
       "3                       1           0.70           1                  N   \n",
       "4                       2           2.40           1                  N   \n",
       "...                   ...            ...         ...                ...   \n",
       "13063789                1           5.67           1               None   \n",
       "13063790                1           1.96           1               None   \n",
       "13063791                1           4.06           1               None   \n",
       "13063792                1           7.20           1                  N   \n",
       "13063793                1           3.20           1                  N   \n",
       "\n",
       "          PULocationID  DOLocationID  payment_type  fare_amount  extra  \\\n",
       "0                  140           140             2          2.5    0.5   \n",
       "1                  186           186             2          3.0    0.5   \n",
       "2                  107           249             1          9.5    0.5   \n",
       "3                  158            90             1          4.5    0.5   \n",
       "4                  234           246             1         11.5    0.5   \n",
       "...                ...           ...           ...          ...    ...   \n",
       "13063789           231            61             1         21.0    0.5   \n",
       "13063790           225           177             2         14.0    0.5   \n",
       "13063791           181            71             1         16.0    0.5   \n",
       "13063792            92            92             2         27.5    0.5   \n",
       "13063793            92            92             1         14.0    0.5   \n",
       "\n",
       "          mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "0             0.5         0.0           0.0                    0.0   \n",
       "1             0.5         0.0           0.0                    0.0   \n",
       "2             0.5         2.1           0.0                    0.0   \n",
       "3             0.5         1.5           0.0                    0.0   \n",
       "4             0.5         2.5           0.0                    0.0   \n",
       "...           ...         ...           ...                    ...   \n",
       "13063789      0.5         4.0           0.0                    0.0   \n",
       "13063790      0.5         0.0           0.0                    0.0   \n",
       "13063791      0.5         0.0           0.0                    0.0   \n",
       "13063792      0.5         0.0           0.0                    0.0   \n",
       "13063793      0.5         2.5           0.0                    0.0   \n",
       "\n",
       "          total_amount congestion_surcharge airport_fee  \n",
       "0                  3.5                 None        None  \n",
       "1                  4.0                 None        None  \n",
       "2                 12.6                 None        None  \n",
       "3                  7.0                 None        None  \n",
       "4                 15.0                 None        None  \n",
       "...                ...                  ...         ...  \n",
       "13063789          26.0                 None        None  \n",
       "13063790          15.0                 None        None  \n",
       "13063791          17.0                 None        None  \n",
       "13063792          28.5                 None        None  \n",
       "13063793          17.5                 None        None  \n",
       "\n",
       "[13063794 rows x 19 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"yellow taxi/yellow_tripdata_2014-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data(parquet_urls):\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    for parquet_url in parquet_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month(parquet_url)\n",
    "    \n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "200776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxi_data():\n",
    "    # download file if not exist\n",
    "    all_urls = get_all_urls_from_taxi_page(TAXI_URL)\n",
    "    all_parquet_urls = filter_taxi_parquet_urls(all_urls)\n",
    "    for url in all_parquet_urls:\n",
    "        response = requests.get(url, stream=True)\n",
    "        file_name = url.split(\"/\")[-1]\n",
    "        local_file_path = os.path.join(\"yellow taxi\", file_name)\n",
    "        if not os.path.exists(local_file_path):\n",
    "            with open(local_file_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "    \n",
    "    \n",
    "    taxi_data = get_and_clean_taxi_data(all_parquet_urls)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c1028d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p4/qjmfcths03bd_jk_rl15fcw40000gn/T/ipykernel_78522/3210650624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtaxi_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_taxi_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/p4/qjmfcths03bd_jk_rl15fcw40000gn/T/ipykernel_78522/3161434419.py\u001b[0m in \u001b[0;36mget_taxi_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtaxi_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_and_clean_taxi_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_parquet_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtaxi_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p4/qjmfcths03bd_jk_rl15fcw40000gn/T/ipykernel_78522/2666832863.py\u001b[0m in \u001b[0;36mget_and_clean_taxi_data\u001b[0;34m(parquet_urls)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# maybe: first try to see if you've downloaded this exact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# file already and saved it before trying again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_and_clean_month\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparquet_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# maybe: if the file hasn't been saved, save it so you can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p4/qjmfcths03bd_jk_rl15fcw40000gn/T/ipykernel_78522/473337361.py\u001b[0m in \u001b[0;36mget_and_clean_month\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"          \n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tpep_pickup_datetime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tpep_dropoff_datetime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PULocationID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DOLocationID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fare_amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filesystem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    633\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "taxi_data = get_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ebd75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df.dropna(how='any')      #remove missing values\n",
    "    df = df.drop(columns=['Unnamed: 0','key','passenger_count'])      #remove unnecessary columns\n",
    "    df = df.loc[df.pickup_longitude.between(-74.242330,-73.717047) & df.dropoff_longitude.between(-74.242330,-73.717047) \n",
    "         & df.pickup_latitude.between(40.560445,40.908524)& df.dropoff_latitude.between(40.560445,40.908524)]\n",
    "          # remove locations out of range\n",
    "    df.reset_index(drop=True, inplace=True)    #reset index\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_DATA)\n",
    "    uber_dataframe = add_distance_column(uber_dataframe)\n",
    "    uber_dataframe[\"pick_date\"] = pd.to_datetime(uber_dataframe['pickup_datetime'])\n",
    "    uber_dataframe[\"year\"] = uber_dataframe[\"pick_date\"].dt.year\n",
    "    uber_dataframe[\"month\"] = uber_dataframe[\"pick_date\"].dt.month\n",
    "    uber_dataframe[\"day\"] = uber_dataframe[\"pick_date\"].dt.day\n",
    "    uber_dataframe[\"hour\"] = uber_dataframe[\"pick_date\"].dt.hour\n",
    "    uber_dataframe[\"dayofweek\"] = uber_dataframe[\"pick_date\"].dt.dayofweek\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339997e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weather_csvs(directory):\n",
    "    csv_files = [file for file in os.listdir(directory) if file.endswith(\".csv\")]\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d990317",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_weather_csvs(WEATHER_CSV_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    we = pd.read_csv(csv_file)\n",
    "    # keep the necessary columns\n",
    "    f1 = ['DATE', 'HourlyPrecipitation', 'HourlyWindSpeed']\n",
    "    we_1 = pd.DataFrame()\n",
    "    for i in f1:\n",
    "        col1=we.loc[:,we.columns.str.contains(i)]\n",
    "        we_1=pd.concat([we_1, col1], axis=1)\n",
    "    hourly_clean= we_1.dropna()\n",
    "    hourly_clean.reset_index(drop=True, inplace=True)\n",
    "    # Add the columns of year, month, day and hour according to the date\n",
    "    hourly_clean[\"DATE\"] = pd.to_datetime(hourly_clean['DATE'])\n",
    "    hourly_clean[\"YEAR\"] = hourly_clean[\"DATE\"].dt.year\n",
    "    hourly_clean[\"MONTH\"] = hourly_clean[\"DATE\"].dt.month\n",
    "    hourly_clean[\"DAY\"] = hourly_clean[\"DATE\"].dt.day\n",
    "    hourly_clean[\"HOUR\"] = hourly_clean[\"DATE\"].dt.hour\n",
    "    hourly_clean.round({'HourlyPrecipitation': 2})\n",
    "    return hourly_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    we = pd.read_csv(csv_file)\n",
    "    # keep the necessary columns\n",
    "    f2 = ['DATE', 'DailySustainedWindSpeed']\n",
    "    we_2 = pd.DataFrame()\n",
    "    for i in f2:\n",
    "        col2=we.loc[:,we.columns.str.contains(i)]\n",
    "        we_2=pd.concat([we_2, col2], axis=1)\n",
    "    daily_clean= we_2.dropna()\n",
    "    daily_clean.reset_index(drop=True, inplace=True)\n",
    "    # Add the columns of year, month, day and hour according to the date\n",
    "    daily_clean[\"DATE\"] = pd.to_datetime(daily_clean['DATE'])\n",
    "    daily_clean[\"YEAR\"] = daily_clean[\"DATE\"].dt.year\n",
    "    daily_clean[\"MONTH\"] = daily_clean[\"DATE\"].dt.month\n",
    "    daily_clean[\"DAY\"] = daily_clean[\"DATE\"].dt.day\n",
    "    daily_clean[\"HOUR\"] = daily_clean[\"DATE\"].dt.hour\n",
    "    return daily_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    weather_csv_files = get_all_weather_csvs(WEATHER_CSV_DIR)\n",
    "    \n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "        \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48216557",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb386ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_data,\n",
    "    \"daily_weather\": daily_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
